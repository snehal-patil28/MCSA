# -*- coding: utf-8 -*-
"""MCSA_anomaly_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GtFYrnfttX-TeJU1vJ8I98mvucI6u3Ki

Motor Current Signature Analysis (MCSA) is a technique used to determine the operating condition of induction motors without interrupting production. Motor current signature analysis is that it is sensing an electrical signal that contains current components. MCSA detect the faults at an early stage and avoid the damage and complete failure of the motor.

# Importing necessary Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import glob

#Data manupulation and handling
import numpy as np
import pandas as pd
from scipy import signal

# Data Visulisation Libraries
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as sci
# %matplotlib inline

# Model and performance
from sklearn.svm import OneClassSVM
from sklearn.metrics import classification_report


#warning filter library
import warnings
warnings.filterwarnings('ignore')

folder_path = '/content'
file_list = glob.glob(folder_path + "/*.txt")

data_collected = []
for i in range(len(file_list)):
   readings = np.genfromtxt(file_list[i], delimiter=',', dtype=int)[:-1]
   data_collected.append(readings)
current_measurements = np.concatenate(data_collected)
print('Total Number of current readings count : ', len(current_measurements))

"""There are several methods which able to detect failures, starting with the most basic (FFT), to the most complex (Gaussian Mixture Model). These have the advantage of being able to be re-used with minor modifications on different data streams, and don't require a lot of known previously classified data

# FFT (Fast Fourier Transform)
"""

print('file_list : ', file_list)
# Make time array

current_array = []
for i in range(len(file_list)):
  print(i)
  timeTrain = np.genfromtxt(file_list[i], delimiter=',', dtype=int)[:-1]
  meanTrain = np.average(timeTrain)
  current_array.append(timeTrain - meanTrain)

print('current_array : ', current_array)

def makeData(time):
    # welch transform
    x1, y1 = signal.welch(time, 10000, nperseg=65535/2)
    # decibel conversion
    y1=20*np.log10(y1)
    # give offset
    y1 = y1 + 100
    # find max and divide by max, then square the value to reduce noise
    maxAmp = max(y1)
    y2 = y1/maxAmp
    y2 = np.square(y2)
    y2 = y2*maxAmp
    # global frequency
    # frequency = x1
    return x1, y2

xx = {}
yy = {}

for i in range(len(file_list)):
  xx[i], yy[i] = makeData(current_array[i])
print('xx : ', xx)
print('yy : ', yy)


def spikes(x, y, label = " "):
    print("")
    print("Data is", label)
    f = x.tolist()
    mag = y.tolist()
    for index, value in enumerate(mag):
        if index > 1 and index < (len(mag) - 1) and (mag[index] > mag[index+1]) and (mag[index] > mag[index - 1]) and (mag[index] > 10):
            print(str(f[index]) + "   " + str(mag[index]))

# Data from Multiple files 
for i in range(len(file_list)):
  file_name = file_list[i].split('/')[-1].replace('.txt', ' ')
  spikes(xx[i], yy[i], label = file_name)

  plt.plot(xx[i], yy[i], label = file_name)


plt.legend()
plt.show()

"""# SVM (Support Vector Machine)

**One-class SVM** is a variation of the SVM that can be used in an unsupervised setting for anomaly detection. Where instead of hyperplane to separate the classes (+ and -ve) draw boundry around data points to find the outliers/anomaly. Outside border to be anomalies.
"""

# Exclding last file to use as Test Data. Remaining data will be Training data

# Make train array 
train_data_collected = []
for i in range(len(file_list)-1):
   readings = np.genfromtxt(file_list[i], delimiter=',', dtype=int)[:-1]
   train_data_collected.append(readings)
current_measurements_train = np.concatenate(train_data_collected)
meanTrain = np.average(current_measurements_train)
current_measurements_train = current_measurements_train - meanTrain

EM_train = current_measurements_train

print('Total Number of current readings train count : ', len(current_measurements_train))

# Make test array 
test_data_collected = np.genfromtxt(file_list[len(file_list)-1], delimiter=',', dtype=int)[:-1]
current_measurements_test = test_data_collected
print('Total Number of current readings Test count : ', len(current_measurements_test))
PR_test = current_measurements_test

def makeData(current):
    # welch transform
    x1, y1 = signal.welch(current, 10000, nperseg=len(current)/2)
    # decibel conversion
    y1=20*np.log10(y1)
    # give offset
    y1 = y1 + 100
    # find max and divide by max, then square the value to reduce noise
    maxAmp = max(y1)
    y2 = y1/maxAmp
    y2 = np.square(y2)
    y2 = y2*maxAmp
    # global frequency
    # frequency = x1
    return x1, y2

freq_train, amp_train = makeData(EM_train)
X_Train = np.vstack((freq_train, amp_train)).T

freq_test, amp_test = makeData(PR_test)
X_Test = np.vstack((freq_test, amp_test)).T

y_train = np.full((len(amp_train)), -1, dtype=int)
y_test = np.full((len(amp_test)), -1, dtype=int)

# print('amp_train  :', amp_train)
# print('amp_test  :', amp_test)

def calculate_y(feature, target, threshold=110):
  for index, val in enumerate(feature):
    if val < threshold:
        target[index] = 1
    else:
        target[index] = -1

calculate_y(amp_train, y_train, 110)
calculate_y(amp_test, y_test, 110)

# Train One-Class Support Vector Machine (SVM) Model
one_class_svm = OneClassSVM(nu=0.1, kernel="poly", gamma=0.1).fit(X_Train)

# Predict the anomalies
prediction  = one_class_svm.predict(X_Test)

# Check the model performance
print(classification_report(y_test, prediction))

"""## Customized prediction with changing threshold value"""

# Increases threshold value 

calculate_y(amp_train, y_train, 115)
calculate_y(amp_test, y_test, 115)

# Predict the anomalies
prediction  = one_class_svm.predict(X_Test)
print('prediction :', prediction)
print('y_test :', y_test )
# Check the model performance
print(classification_report(y_test, prediction))

"""Recall 0.67 when threshold value 110 (y-axis) amp after scaling(actual 220) . Recall get increases to 1.00 on increases the threshold 115."""